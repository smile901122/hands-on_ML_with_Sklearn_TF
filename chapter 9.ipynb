{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建一个计算图并在会话中执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(3, name='x')\n",
    "y = tf.Variable(4, name='y')\n",
    "f = x * x * y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 管理图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# 创建的结点会自动添加到默认图上，如果想要管理多个互不依赖的图，可以创建一个新的图，用with块临时将它设置为默认图\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "    \n",
    "print(x2.graph is graph)\n",
    "print(x2.graph is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 节点的生命周期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在图的每次执行过程中，所有的节点值都会被丢弃，但是变量的值不会，因为变量的值是由会话维护的。变量的生命周期从初始化器的执行开始，到关闭会话结束。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# 上面在对y和z求值时会重复计算w和x重复求值，若不希望对y和z重复求值，则可以告诉TF在一次图的执行中完成y和z的求值\n",
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow中的线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.7171074e+01]\n",
      " [ 4.3633682e-01]\n",
      " [ 9.3871783e-03]\n",
      " [-1.0717344e-01]\n",
      " [ 6.4540231e-01]\n",
      " [-4.1238391e-06]\n",
      " [-3.7809242e-03]\n",
      " [-4.2373490e-01]\n",
      " [-4.3720812e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "# np.c_中的c是column（列）的缩写，是按列叠加两个矩阵的意思，也可以说是按行连接两个矩阵，就是把两矩阵左右相加，要求行数相等，类似于pandas中的merge()\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)  # 正规解\n",
    "\n",
    "# 与numpy计算正规方程相比，使用tf可以自动将计算分发到gpu上去，如果可以的话\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    print(theta_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对特征向量做归一化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(housing_data_plus_bias)\n",
    "scaler_housing_data_plus_bias = scaler.transform(housing_data_plus_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现梯度下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 手工计算梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  mse= 5.849907\n",
      "epoch:  100  mse= 4.8064346\n",
      "epoch:  200  mse= 4.8034205\n",
      "epoch:  300  mse= 4.803268\n",
      "epoch:  400  mse= 4.8032556\n",
      "epoch:  500  mse= 4.8032537\n",
      "epoch:  600  mse= 4.8032546\n",
      "epoch:  700  mse= 4.803254\n",
      "epoch:  800  mse= 4.8032546\n",
      "epoch:  900  mse= 4.8032537\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "X = tf.constant(scaler_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "gradients = 2 / m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "#             print('theta=', theta.eval())\n",
    "            print('epoch: ', epoch, ' mse=', mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用自动微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  mse= 5.299648\n",
      "epoch:  100  mse= 4.81614\n",
      "epoch:  200  mse= 4.804929\n",
      "epoch:  300  mse= 4.8035064\n",
      "epoch:  400  mse= 4.8032937\n",
      "epoch:  500  mse= 4.80326\n",
      "epoch:  600  mse= 4.8032546\n",
      "epoch:  700  mse= 4.8032546\n",
      "epoch:  800  mse= 4.8032537\n",
      "epoch:  900  mse= 4.8032537\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "X = tf.constant(scaler_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "#             print('theta=', theta.eval())\n",
    "            print('epoch: ', epoch, ' mse=', mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  mse= 8.597808\n",
      "epoch:  100  mse= 4.8066044\n",
      "epoch:  200  mse= 4.8033886\n",
      "epoch:  300  mse= 4.803261\n",
      "epoch:  400  mse= 4.803254\n",
      "epoch:  500  mse= 4.8032537\n",
      "epoch:  600  mse= 4.8032546\n",
      "epoch:  700  mse= 4.803254\n",
      "epoch:  800  mse= 4.803254\n",
      "epoch:  900  mse= 4.8032537\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "X = tf.constant(scaler_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "#             print('theta=', theta.eval())\n",
    "            print('epoch: ', epoch, ' mse=', mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 给训练算法提供数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch index:  0  mse= 7.2183957\n",
      "batch index:  1  mse= 6.274323\n",
      "batch index:  2  mse= 5.782699\n",
      "batch index:  3  mse= 5.5087514\n",
      "batch index:  4  mse= 5.3468623\n",
      "batch index:  5  mse= 5.246343\n",
      "batch index:  6  mse= 5.181192\n",
      "batch index:  7  mse= 5.1372404\n",
      "batch index:  8  mse= 5.1063743\n",
      "batch index:  9  mse= 5.083768\n",
      "batch index:  10  mse= 5.066475\n",
      "batch index:  11  mse= 5.052661\n",
      "batch index:  12  mse= 5.0411663\n",
      "batch index:  13  mse= 5.0312524\n",
      "batch index:  14  mse= 5.0224433\n",
      "batch index:  15  mse= 5.014431\n",
      "batch index:  16  mse= 5.007013\n",
      "batch index:  17  mse= 5.000056\n",
      "batch index:  18  mse= 4.9934697\n",
      "batch index:  19  mse= 4.987194\n",
      "batch index:  20  mse= 4.9811854\n",
      "epoch:  0  mse= 4.9754143\n",
      "batch index:  0  mse= 4.9754143\n",
      "batch index:  1  mse= 4.969859\n",
      "batch index:  2  mse= 4.9645023\n",
      "batch index:  3  mse= 4.9593325\n",
      "batch index:  4  mse= 4.9543386\n",
      "batch index:  5  mse= 4.949511\n",
      "batch index:  6  mse= 4.9448447\n",
      "batch index:  7  mse= 4.9403296\n",
      "batch index:  8  mse= 4.9359627\n",
      "batch index:  9  mse= 4.9317384\n",
      "batch index:  10  mse= 4.9276495\n",
      "batch index:  11  mse= 4.923693\n",
      "batch index:  12  mse= 4.9198637\n",
      "batch index:  13  mse= 4.9161577\n",
      "batch index:  14  mse= 4.9125705\n",
      "batch index:  15  mse= 4.9090986\n",
      "batch index:  16  mse= 4.905739\n",
      "batch index:  17  mse= 4.902487\n",
      "batch index:  18  mse= 4.899338\n",
      "batch index:  19  mse= 4.896291\n",
      "batch index:  20  mse= 4.8933406\n",
      "epoch:  1  mse= 4.8904843\n",
      "batch index:  0  mse= 4.8904843\n",
      "batch index:  1  mse= 4.88772\n",
      "batch index:  2  mse= 4.8850446\n",
      "batch index:  3  mse= 4.882454\n",
      "batch index:  4  mse= 4.8799467\n",
      "batch index:  5  mse= 4.87752\n",
      "batch index:  6  mse= 4.8751698\n",
      "batch index:  7  mse= 4.872895\n",
      "batch index:  8  mse= 4.870694\n",
      "batch index:  9  mse= 4.868562\n",
      "batch index:  10  mse= 4.8664985\n",
      "batch index:  11  mse= 4.864501\n",
      "batch index:  12  mse= 4.8625674\n",
      "batch index:  13  mse= 4.8606944\n",
      "batch index:  14  mse= 4.858883\n",
      "batch index:  15  mse= 4.8571277\n",
      "batch index:  16  mse= 4.855429\n",
      "batch index:  17  mse= 4.8537846\n",
      "batch index:  18  mse= 4.852193\n",
      "batch index:  19  mse= 4.8506517\n",
      "batch index:  20  mse= 4.849159\n",
      "epoch:  2  mse= 4.847716\n",
      "batch index:  0  mse= 4.847716\n",
      "batch index:  1  mse= 4.8463154\n",
      "batch index:  2  mse= 4.844961\n",
      "batch index:  3  mse= 4.843651\n",
      "batch index:  4  mse= 4.842382\n",
      "batch index:  5  mse= 4.8411536\n",
      "batch index:  6  mse= 4.839964\n",
      "batch index:  7  mse= 4.838812\n",
      "batch index:  8  mse= 4.837696\n",
      "batch index:  9  mse= 4.8366165\n",
      "batch index:  10  mse= 4.835571\n",
      "batch index:  11  mse= 4.8345585\n",
      "batch index:  12  mse= 4.8335795\n",
      "batch index:  13  mse= 4.832629\n",
      "batch index:  14  mse= 4.831711\n",
      "batch index:  15  mse= 4.8308206\n",
      "batch index:  16  mse= 4.8299594\n",
      "batch index:  17  mse= 4.829125\n",
      "batch index:  18  mse= 4.8283176\n",
      "batch index:  19  mse= 4.827536\n",
      "batch index:  20  mse= 4.8267784\n",
      "epoch:  3  mse= 4.8260446\n",
      "batch index:  0  mse= 4.8260446\n",
      "batch index:  1  mse= 4.825335\n",
      "batch index:  2  mse= 4.8246474\n",
      "batch index:  3  mse= 4.823982\n",
      "batch index:  4  mse= 4.8233366\n",
      "batch index:  5  mse= 4.822713\n",
      "batch index:  6  mse= 4.8221083\n",
      "batch index:  7  mse= 4.821522\n",
      "batch index:  8  mse= 4.8209558\n",
      "batch index:  9  mse= 4.820406\n",
      "batch index:  10  mse= 4.819875\n",
      "batch index:  11  mse= 4.8193593\n",
      "batch index:  12  mse= 4.8188605\n",
      "batch index:  13  mse= 4.818378\n",
      "batch index:  14  mse= 4.8179097\n",
      "batch index:  15  mse= 4.817457\n",
      "batch index:  16  mse= 4.8170185\n",
      "batch index:  17  mse= 4.816593\n",
      "batch index:  18  mse= 4.816182\n",
      "batch index:  19  mse= 4.815783\n",
      "batch index:  20  mse= 4.8153973\n",
      "epoch:  4  mse= 4.815024\n",
      "batch index:  0  mse= 4.815024\n",
      "batch index:  1  mse= 4.8146615\n",
      "batch index:  2  mse= 4.814311\n",
      "batch index:  3  mse= 4.8139706\n",
      "batch index:  4  mse= 4.8136415\n",
      "batch index:  5  mse= 4.8133225\n",
      "batch index:  6  mse= 4.813014\n",
      "batch index:  7  mse= 4.812715\n",
      "batch index:  8  mse= 4.8124256\n",
      "batch index:  9  mse= 4.8121448\n",
      "batch index:  10  mse= 4.811873\n",
      "batch index:  11  mse= 4.8116093\n",
      "batch index:  12  mse= 4.8113556\n",
      "batch index:  13  mse= 4.8111076\n",
      "batch index:  14  mse= 4.810868\n",
      "batch index:  15  mse= 4.810637\n",
      "batch index:  16  mse= 4.810412\n",
      "batch index:  17  mse= 4.8101935\n",
      "batch index:  18  mse= 4.8099837\n",
      "batch index:  19  mse= 4.809779\n",
      "batch index:  20  mse= 4.8095813\n",
      "epoch:  5  mse= 4.8093896\n",
      "batch index:  0  mse= 4.8093896\n",
      "batch index:  1  mse= 4.809203\n",
      "batch index:  2  mse= 4.809023\n",
      "batch index:  3  mse= 4.80885\n",
      "batch index:  4  mse= 4.808681\n",
      "batch index:  5  mse= 4.8085175\n",
      "batch index:  6  mse= 4.808358\n",
      "batch index:  7  mse= 4.808204\n",
      "batch index:  8  mse= 4.808055\n",
      "batch index:  9  mse= 4.807911\n",
      "batch index:  10  mse= 4.8077717\n",
      "batch index:  11  mse= 4.8076353\n",
      "batch index:  12  mse= 4.8075047\n",
      "batch index:  13  mse= 4.8073773\n",
      "batch index:  14  mse= 4.8072534\n",
      "batch index:  15  mse= 4.8071337\n",
      "batch index:  16  mse= 4.8070183\n",
      "batch index:  17  mse= 4.806906\n",
      "batch index:  18  mse= 4.8067975\n",
      "batch index:  19  mse= 4.8066916\n",
      "batch index:  20  mse= 4.8065896\n",
      "epoch:  6  mse= 4.8064904\n",
      "batch index:  0  mse= 4.8064904\n",
      "batch index:  1  mse= 4.8063946\n",
      "batch index:  2  mse= 4.8063016\n",
      "batch index:  3  mse= 4.806211\n",
      "batch index:  4  mse= 4.8061237\n",
      "batch index:  5  mse= 4.8060393\n",
      "batch index:  6  mse= 4.805957\n",
      "batch index:  7  mse= 4.8058763\n",
      "batch index:  8  mse= 4.805799\n",
      "batch index:  9  mse= 4.805725\n",
      "batch index:  10  mse= 4.805652\n",
      "batch index:  11  mse= 4.805581\n",
      "batch index:  12  mse= 4.8055134\n",
      "batch index:  13  mse= 4.8054476\n",
      "batch index:  14  mse= 4.8053837\n",
      "batch index:  15  mse= 4.8053217\n",
      "batch index:  16  mse= 4.8052616\n",
      "batch index:  17  mse= 4.805203\n",
      "batch index:  18  mse= 4.8051453\n",
      "batch index:  19  mse= 4.805091\n",
      "batch index:  20  mse= 4.805038\n",
      "epoch:  7  mse= 4.8049855\n",
      "batch index:  0  mse= 4.8049855\n",
      "batch index:  1  mse= 4.804937\n",
      "batch index:  2  mse= 4.8048873\n",
      "batch index:  3  mse= 4.8048396\n",
      "batch index:  4  mse= 4.8047943\n",
      "batch index:  5  mse= 4.8047504\n",
      "batch index:  6  mse= 4.804707\n",
      "batch index:  7  mse= 4.8046656\n",
      "batch index:  8  mse= 4.8046246\n",
      "batch index:  9  mse= 4.804585\n",
      "batch index:  10  mse= 4.8045473\n",
      "batch index:  11  mse= 4.804511\n",
      "batch index:  12  mse= 4.804475\n",
      "batch index:  13  mse= 4.80444\n",
      "batch index:  14  mse= 4.8044066\n",
      "batch index:  15  mse= 4.8043733\n",
      "batch index:  16  mse= 4.8043423\n",
      "batch index:  17  mse= 4.8043113\n",
      "batch index:  18  mse= 4.8042808\n",
      "batch index:  19  mse= 4.804252\n",
      "batch index:  20  mse= 4.804224\n",
      "epoch:  8  mse= 4.8041964\n",
      "batch index:  0  mse= 4.8041964\n",
      "batch index:  1  mse= 4.8041706\n",
      "batch index:  2  mse= 4.804145\n",
      "batch index:  3  mse= 4.8041205\n",
      "batch index:  4  mse= 4.8040957\n",
      "batch index:  5  mse= 4.8040714\n",
      "batch index:  6  mse= 4.804049\n",
      "batch index:  7  mse= 4.8040276\n",
      "batch index:  8  mse= 4.8040056\n",
      "batch index:  9  mse= 4.803985\n",
      "batch index:  10  mse= 4.803965\n",
      "batch index:  11  mse= 4.803945\n",
      "batch index:  12  mse= 4.8039255\n",
      "batch index:  13  mse= 4.803907\n",
      "batch index:  14  mse= 4.8038898\n",
      "batch index:  15  mse= 4.803872\n",
      "batch index:  16  mse= 4.803855\n",
      "batch index:  17  mse= 4.8038387\n",
      "batch index:  18  mse= 4.803823\n",
      "batch index:  19  mse= 4.8038073\n",
      "batch index:  20  mse= 4.803792\n",
      "epoch:  9  mse= 4.8037777\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "learning_rate = 0.1\n",
    "\n",
    "# 创建占位符节点\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name='X')\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name='y')\n",
    "\n",
    "batch_size = 1000\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "# 创建batch\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index) \n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "    return scaler_housing_data_plus_bias[indices] , housing.target.reshape(-1, 1)[indices]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            print('batch index: ', batch_index, ' mse=', mse.eval())\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        print('epoch: ', epoch, ' mse=', mse.eval())\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存和恢复模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  mse= 5.836144\n",
      "epoch:  100  mse= 4.8203287\n",
      "epoch:  200  mse= 4.8043103\n",
      "epoch:  300  mse= 4.8033605\n",
      "epoch:  400  mse= 4.803268\n",
      "epoch:  500  mse= 4.8032556\n",
      "epoch:  600  mse= 4.8032537\n",
      "epoch:  700  mse= 4.803253\n",
      "epoch:  800  mse= 4.803254\n",
      "epoch:  900  mse= 4.8032537\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "X = tf.constant(scaler_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# saver\n",
    "saver = tf.train.Saver()\n",
    "# 按照变量名保存和恢复变量\n",
    "# saver = tf.train.Saver({'weight': theta})\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print('epoch: ', epoch, ' mse=', mse.eval())\n",
    "            saver.save(sess, 'model/model.ckpt')\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    saver.save(sess, 'model/model_final.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from model/model_final.ckpt\n",
      "4.8032537\n"
     ]
    }
   ],
   "source": [
    "# 恢复\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model/model_final.ckpt')\n",
    "    mse = sess.run(mse)\n",
    "    print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用TensorBoard来可视化图和训练曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\n\\x0c\\n\\x05MSE_5\\x15X}\\xfd@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15\\x1dZ\\x99@'\n",
      "b\"\\n\\x0c\\n\\x05MSE_5\\x15'\\xd8\\xa3@\"\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15/i\\xa9@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15w\\xc6\\x9f@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15)r\\x9e@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x150\\xe2\\x9f@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15L\\x8e\\x9c@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15\\xc8g\\x95@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15\\x8d\\xd5\\x9e@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15\\xb0C\\xa0@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15\\xe2\\xd4\\xa0@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x151i\\x9d@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15\\xa6\\x92\\x98@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15\\x16\\xe7\\x90@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15\\x8f\\xdc\\x97@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15o\\x7f\\x9f@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x157\\x07\\x98@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15\\x00\\xc4\\x95@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15D\\xd5\\x95@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15\\xc3\\x91\\x9b@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15\\x7f_\\x99@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15mA\\x9e@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15\\xe9\\x94\\x95@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15\\xee\\x98\\x99@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15\\xf8\\x8e\\x9a@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15w\\xb8\\x98@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15/\\x8d\\x96@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15\\xb4e\\x9b@'\n",
      "b'\\n\\x0c\\n\\x05MSE_5\\x15\\x8f\\x1e\\x99@'\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime('%Y%m%d%H%M%S')\n",
    "root_logdir = 'tf_logs'\n",
    "logdir = '{}/run-{}/'.format(root_logdir, now)\n",
    "\n",
    "n_epochs = 10\n",
    "learning_rate = 0.1\n",
    "\n",
    "# 创建占位符节点\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name='X')\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name='y')\n",
    "\n",
    "batch_size = 1000\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 创建batch\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index) \n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "    return scaler_housing_data_plus_bias[indices] , housing.target.reshape(-1, 1)[indices]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                print(summary_str)\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "    best_theta = theta.eval()\n",
    "    file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 启动 tensorboard 服务器\n",
    "```\n",
    "tensorboard --logdir tf_logs/\n",
    "```\n",
    "- 浏览器中输入 [http://localhost:6006]() 即可看到 tensorboard 界面"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 命名作用域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_loss/sub\n",
      "my_loss/mse\n"
     ]
    }
   ],
   "source": [
    "# 在这个作用域中定义的每个操作现在都有一个 ‘my_loss/’ 前缀\n",
    "with tf.name_scope('my_loss') as scope:\n",
    "    error = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "    \n",
    "print(error.op.name)\n",
    "print(mse.op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模块化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    w_shape = (int(X.get_shape()[1]), 1)\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name='weights')\n",
    "    b = tf.Variable(0.0, name='bias')\n",
    "    z = tf.add(tf.matmul(X, w), b, name='z')\n",
    "    \n",
    "    return tf.maximum(z, 0., name='relu')\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name='output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 共享变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想要在图的不同组件中共享变量：\n",
    "- 最简单的做法是先创建，然后将其作为参数传递给需要他的函数。但是，如果有太多的类似的共享参数，则参数传递便会很痛苦\n",
    "    ```\n",
    "    def relu(X, threshold):\n",
    "    ```\n",
    "\n",
    "- 也可以在第一次调用时将共享变量设置为函数的一个属性\n",
    "    ```\n",
    "    def relu(X):\n",
    "        if not hasattr(relu, 'threshold'):\n",
    "            relu.threshold = tf.Variable(0.0, name='max')\n",
    "    ```\n",
    "    \n",
    "- TF提供：\n",
    "    如果共享变量不存在，该方法先通过get_variable()函数创建共享变量；如果已经存在了，就复用该共享变量。期望的行为通过当前variable_scope()的一个属性来控制（创建或者复用）\n",
    "    ```\n",
    "    with tf.variable_scope('relu'):\n",
    "        threshold = tf.get_variable('threshold', shape=(), initializer=tf.constant_initilizer(0.0))\n",
    "    ```\n",
    "    如果这个变量之前已经被get_variable()调用创建过，这里会抛出一个异常。这种机制避免由于误操作而复用变量。如果要复用一个变量，需要通过设置变量作用域的reuse属性为True来显式的实现\n",
    "    ```\n",
    "    with tf.variable_scope('relu', reuse=True):\n",
    "        threshold = tf.get_variable('threshold')\n",
    "    ```\n",
    "    这段代码会获取既有的‘relu/threshold’变量，如果该变量不存在，或者在调用get_variable()时没有创建成功，那么会抛出一个异常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    w_shape = (int(X.get_shape()[1]), 1)\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name='weights')\n",
    "    b = tf.Variable(0.0, name='bias')\n",
    "    z = tf.add(tf.matmul(X, w), b, name='z')\n",
    "    with tf.variable_scope('relu', reuse=True):\n",
    "        threshold = tf.get_variable('threshold')\n",
    "    return tf.maximum(z, threshold, name='max')\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
    "with tf.variable_scope('relu', reuse=tf.AUTO_REUSE):\n",
    "      threshold = tf.get_variable('threshold', shape=(), initializer=tf.constant_initializer(0.0))\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
