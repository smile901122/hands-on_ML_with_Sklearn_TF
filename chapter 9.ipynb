{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建一个计算图并在会话中执行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.Variable(3, name='x')\n",
    "y = tf.Variable(4, name='y')\n",
    "f = x * x * y + y + 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    result = f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    result = f.eval()\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 管理图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = tf.Variable(1)\n",
    "x1.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# 创建的结点会自动添加到默认图上，如果想要管理多个互不依赖的图，可以创建一个新的图，用with块临时将它设置为默认图\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2 = tf.Variable(2)\n",
    "    \n",
    "print(x2.graph is graph)\n",
    "print(x2.graph is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 节点的生命周期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "w = tf.constant(3)\n",
    "x = w + 2\n",
    "y = x + 5\n",
    "z = x * 3\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(y.eval())\n",
    "    print(z.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在图的每次执行过程中，所有的节点值都会被丢弃，但是变量的值不会，因为变量的值是由会话维护的。变量的生命周期从初始化器的执行开始，到关闭会话结束。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# 上面在对y和z求值时会重复计算w和x重复求值，若不希望对y和z重复求值，则可以告诉TF在一次图的执行中完成y和z的求值\n",
    "with tf.Session() as sess:\n",
    "    y_val, z_val = sess.run([y, z])\n",
    "    print(y_val)\n",
    "    print(z_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow中的线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.7171074e+01]\n",
      " [ 4.3633682e-01]\n",
      " [ 9.3871783e-03]\n",
      " [-1.0717344e-01]\n",
      " [ 6.4540231e-01]\n",
      " [-4.1238391e-06]\n",
      " [-3.7809242e-03]\n",
      " [-4.2373490e-01]\n",
      " [-4.3720812e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "m, n = housing.data.shape\n",
    "# np.c_中的c是column（列）的缩写，是按列叠加两个矩阵的意思，也可以说是按行连接两个矩阵，就是把两矩阵左右相加，要求行数相等，类似于pandas中的merge()\n",
    "housing_data_plus_bias = np.c_[np.ones((m, 1)), housing.data]\n",
    "\n",
    "X = tf.constant(housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "XT = tf.transpose(X)\n",
    "theta = tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(XT, X)), XT), y)  # 正规解\n",
    "\n",
    "# 与numpy计算正规方程相比，使用tf可以自动将计算分发到gpu上去，如果可以的话\n",
    "with tf.Session() as sess:\n",
    "    theta_value = theta.eval()\n",
    "    print(theta_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对特征向量做归一化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler().fit(housing_data_plus_bias)\n",
    "scaler_housing_data_plus_bias = scaler.transform(housing_data_plus_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实现梯度下降"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 手工计算梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  mse= 6.684296\n",
      "epoch:  100  mse= 4.8095016\n",
      "epoch:  200  mse= 4.8035173\n",
      "epoch:  300  mse= 4.803269\n",
      "epoch:  400  mse= 4.803256\n",
      "epoch:  500  mse= 4.8032546\n",
      "epoch:  600  mse= 4.8032537\n",
      "epoch:  700  mse= 4.8032537\n",
      "epoch:  800  mse= 4.8032546\n",
      "epoch:  900  mse= 4.8032537\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "X = tf.constant(scaler_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "gradients = 2 / m * tf.matmul(tf.transpose(X), error)\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "#             print('theta=', theta.eval())\n",
    "            print('epoch: ', epoch, ' mse=', mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用自动微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  mse= 9.153329\n",
      "epoch:  100  mse= 4.8080773\n",
      "epoch:  200  mse= 4.8034444\n",
      "epoch:  300  mse= 4.803262\n",
      "epoch:  400  mse= 4.803254\n",
      "epoch:  500  mse= 4.8032537\n",
      "epoch:  600  mse= 4.8032546\n",
      "epoch:  700  mse= 4.803254\n",
      "epoch:  800  mse= 4.8032537\n",
      "epoch:  900  mse= 4.8032537\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "n_epochs = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "X = tf.constant(scaler_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "gradients = tf.gradients(mse, [theta])[0]\n",
    "training_op = tf.assign(theta, theta - learning_rate * gradients)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "#             print('theta=', theta.eval())\n",
    "            print('epoch: ', epoch, ' mse=', mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  mse= 6.417272\n",
      "epoch:  100  mse= 4.827496\n",
      "epoch:  200  mse= 4.805356\n",
      "epoch:  300  mse= 4.803524\n",
      "epoch:  400  mse= 4.803294\n",
      "epoch:  500  mse= 4.8032603\n",
      "epoch:  600  mse= 4.8032546\n",
      "epoch:  700  mse= 4.8032546\n",
      "epoch:  800  mse= 4.8032537\n",
      "epoch:  900  mse= 4.8032537\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "X = tf.constant(scaler_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "#             print('theta=', theta.eval())\n",
    "            print('epoch: ', epoch, ' mse=', mse.eval())\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 给训练算法提供数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch index:  0  mse= 7.4008985\n",
      "batch index:  1  mse= 6.282696\n",
      "batch index:  2  mse= 5.685436\n",
      "batch index:  3  mse= 5.352896\n",
      "batch index:  4  mse= 5.161776\n",
      "batch index:  5  mse= 5.049202\n",
      "batch index:  6  mse= 4.981522\n",
      "batch index:  7  mse= 4.9400396\n",
      "batch index:  8  mse= 4.914078\n",
      "batch index:  9  mse= 4.8974237\n",
      "batch index:  10  mse= 4.886406\n",
      "batch index:  11  mse= 4.8788342\n",
      "batch index:  12  mse= 4.873391\n",
      "batch index:  13  mse= 4.8692775\n",
      "batch index:  14  mse= 4.8660083\n",
      "batch index:  15  mse= 4.8632836\n",
      "batch index:  16  mse= 4.86092\n",
      "batch index:  17  mse= 4.858804\n",
      "batch index:  18  mse= 4.856863\n",
      "batch index:  19  mse= 4.855051\n",
      "batch index:  20  mse= 4.85334\n",
      "epoch:  0  mse= 4.8517118\n",
      "batch index:  0  mse= 4.8517118\n",
      "batch index:  1  mse= 4.850152\n",
      "batch index:  2  mse= 4.848654\n",
      "batch index:  3  mse= 4.847211\n",
      "batch index:  4  mse= 4.8458195\n",
      "batch index:  5  mse= 4.844475\n",
      "batch index:  6  mse= 4.8431754\n",
      "batch index:  7  mse= 4.841917\n",
      "batch index:  8  mse= 4.840702\n",
      "batch index:  9  mse= 4.839525\n",
      "batch index:  10  mse= 4.838386\n",
      "batch index:  11  mse= 4.8372846\n",
      "batch index:  12  mse= 4.8362174\n",
      "batch index:  13  mse= 4.835185\n",
      "batch index:  14  mse= 4.834184\n",
      "batch index:  15  mse= 4.8332167\n",
      "batch index:  16  mse= 4.832279\n",
      "batch index:  17  mse= 4.8313713\n",
      "batch index:  18  mse= 4.830493\n",
      "batch index:  19  mse= 4.8296423\n",
      "batch index:  20  mse= 4.828819\n",
      "epoch:  1  mse= 4.8280206\n",
      "batch index:  0  mse= 4.8280206\n",
      "batch index:  1  mse= 4.8272486\n",
      "batch index:  2  mse= 4.8264995\n",
      "batch index:  3  mse= 4.825776\n",
      "batch index:  4  mse= 4.825075\n",
      "batch index:  5  mse= 4.8243957\n",
      "batch index:  6  mse= 4.823738\n",
      "batch index:  7  mse= 4.823101\n",
      "batch index:  8  mse= 4.8224845\n",
      "batch index:  9  mse= 4.821888\n",
      "batch index:  10  mse= 4.821309\n",
      "batch index:  11  mse= 4.8207498\n",
      "batch index:  12  mse= 4.820207\n",
      "batch index:  13  mse= 4.819681\n",
      "batch index:  14  mse= 4.8191724\n",
      "batch index:  15  mse= 4.81868\n",
      "batch index:  16  mse= 4.818203\n",
      "batch index:  17  mse= 4.817741\n",
      "batch index:  18  mse= 4.8172936\n",
      "batch index:  19  mse= 4.8168607\n",
      "batch index:  20  mse= 4.816441\n",
      "epoch:  2  mse= 4.816034\n",
      "batch index:  0  mse= 4.816034\n",
      "batch index:  1  mse= 4.8156404\n",
      "batch index:  2  mse= 4.8152595\n",
      "batch index:  3  mse= 4.81489\n",
      "batch index:  4  mse= 4.8145328\n",
      "batch index:  5  mse= 4.814185\n",
      "batch index:  6  mse= 4.81385\n",
      "batch index:  7  mse= 4.813525\n",
      "batch index:  8  mse= 4.81321\n",
      "batch index:  9  mse= 4.812905\n",
      "batch index:  10  mse= 4.8126097\n",
      "batch index:  11  mse= 4.812323\n",
      "batch index:  12  mse= 4.8120465\n",
      "batch index:  13  mse= 4.8117776\n",
      "batch index:  14  mse= 4.8115172\n",
      "batch index:  15  mse= 4.811266\n",
      "batch index:  16  mse= 4.811021\n",
      "batch index:  17  mse= 4.8107853\n",
      "batch index:  18  mse= 4.8105555\n",
      "batch index:  19  mse= 4.8103333\n",
      "batch index:  20  mse= 4.810118\n",
      "epoch:  3  mse= 4.8099103\n",
      "batch index:  0  mse= 4.8099103\n",
      "batch index:  1  mse= 4.809709\n",
      "batch index:  2  mse= 4.809512\n",
      "batch index:  3  mse= 4.8093233\n",
      "batch index:  4  mse= 4.8091397\n",
      "batch index:  5  mse= 4.808962\n",
      "batch index:  6  mse= 4.808789\n",
      "batch index:  7  mse= 4.8086224\n",
      "batch index:  8  mse= 4.8084598\n",
      "batch index:  9  mse= 4.808304\n",
      "batch index:  10  mse= 4.808152\n",
      "batch index:  11  mse= 4.8080053\n",
      "batch index:  12  mse= 4.807862\n",
      "batch index:  13  mse= 4.8077235\n",
      "batch index:  14  mse= 4.8075895\n",
      "batch index:  15  mse= 4.80746\n",
      "batch index:  16  mse= 4.8073344\n",
      "batch index:  17  mse= 4.807213\n",
      "batch index:  18  mse= 4.807094\n",
      "batch index:  19  mse= 4.8069797\n",
      "batch index:  20  mse= 4.8068686\n",
      "epoch:  4  mse= 4.806761\n",
      "batch index:  0  mse= 4.806761\n",
      "batch index:  1  mse= 4.806657\n",
      "batch index:  2  mse= 4.8065557\n",
      "batch index:  3  mse= 4.806458\n",
      "batch index:  4  mse= 4.8063626\n",
      "batch index:  5  mse= 4.806271\n",
      "batch index:  6  mse= 4.8061814\n",
      "batch index:  7  mse= 4.8060946\n",
      "batch index:  8  mse= 4.806012\n",
      "batch index:  9  mse= 4.8059297\n",
      "batch index:  10  mse= 4.8058515\n",
      "batch index:  11  mse= 4.805775\n",
      "batch index:  12  mse= 4.805701\n",
      "batch index:  13  mse= 4.8056293\n",
      "batch index:  14  mse= 4.8055596\n",
      "batch index:  15  mse= 4.8054924\n",
      "batch index:  16  mse= 4.8054266\n",
      "batch index:  17  mse= 4.805363\n",
      "batch index:  18  mse= 4.8053017\n",
      "batch index:  19  mse= 4.8052416\n",
      "batch index:  20  mse= 4.805185\n",
      "epoch:  5  mse= 4.805127\n",
      "batch index:  0  mse= 4.805127\n",
      "batch index:  1  mse= 4.8050747\n",
      "batch index:  2  mse= 4.805021\n",
      "batch index:  3  mse= 4.80497\n",
      "batch index:  4  mse= 4.8049207\n",
      "batch index:  5  mse= 4.804872\n",
      "batch index:  6  mse= 4.804826\n",
      "batch index:  7  mse= 4.80478\n",
      "batch index:  8  mse= 4.8047366\n",
      "batch index:  9  mse= 4.804694\n",
      "batch index:  10  mse= 4.8046536\n",
      "batch index:  11  mse= 4.804612\n",
      "batch index:  12  mse= 4.8045745\n",
      "batch index:  13  mse= 4.804536\n",
      "batch index:  14  mse= 4.8044996\n",
      "batch index:  15  mse= 4.8044643\n",
      "batch index:  16  mse= 4.8044295\n",
      "batch index:  17  mse= 4.804397\n",
      "batch index:  18  mse= 4.8043647\n",
      "batch index:  19  mse= 4.8043327\n",
      "batch index:  20  mse= 4.8043027\n",
      "epoch:  6  mse= 4.8042727\n",
      "batch index:  0  mse= 4.8042727\n",
      "batch index:  1  mse= 4.804244\n",
      "batch index:  2  mse= 4.804216\n",
      "batch index:  3  mse= 4.804189\n",
      "batch index:  4  mse= 4.804163\n",
      "batch index:  5  mse= 4.804137\n",
      "batch index:  6  mse= 4.804113\n",
      "batch index:  7  mse= 4.8040886\n",
      "batch index:  8  mse= 4.804066\n",
      "batch index:  9  mse= 4.8040433\n",
      "batch index:  10  mse= 4.8040214\n",
      "batch index:  11  mse= 4.8039994\n",
      "batch index:  12  mse= 4.80398\n",
      "batch index:  13  mse= 4.80396\n",
      "batch index:  14  mse= 4.8039393\n",
      "batch index:  15  mse= 4.803921\n",
      "batch index:  16  mse= 4.8039026\n",
      "batch index:  17  mse= 4.8038845\n",
      "batch index:  18  mse= 4.803868\n",
      "batch index:  19  mse= 4.803851\n",
      "batch index:  20  mse= 4.8038344\n",
      "epoch:  7  mse= 4.803818\n",
      "batch index:  0  mse= 4.803818\n",
      "batch index:  1  mse= 4.8038034\n",
      "batch index:  2  mse= 4.803789\n",
      "batch index:  3  mse= 4.803774\n",
      "batch index:  4  mse= 4.8037596\n",
      "batch index:  5  mse= 4.803746\n",
      "batch index:  6  mse= 4.8037324\n",
      "batch index:  7  mse= 4.8037205\n",
      "batch index:  8  mse= 4.803708\n",
      "batch index:  9  mse= 4.8036957\n",
      "batch index:  10  mse= 4.8036838\n",
      "batch index:  11  mse= 4.8036723\n",
      "batch index:  12  mse= 4.8036604\n",
      "batch index:  13  mse= 4.8036504\n",
      "batch index:  14  mse= 4.80364\n",
      "batch index:  15  mse= 4.8036294\n",
      "batch index:  16  mse= 4.8036194\n",
      "batch index:  17  mse= 4.8036094\n",
      "batch index:  18  mse= 4.8036003\n",
      "batch index:  19  mse= 4.8035913\n",
      "batch index:  20  mse= 4.803582\n",
      "epoch:  8  mse= 4.803574\n",
      "batch index:  0  mse= 4.803574\n",
      "batch index:  1  mse= 4.803565\n",
      "batch index:  2  mse= 4.8035574\n",
      "batch index:  3  mse= 4.803549\n",
      "batch index:  4  mse= 4.8035417\n",
      "batch index:  5  mse= 4.8035345\n",
      "batch index:  6  mse= 4.8035274\n",
      "batch index:  7  mse= 4.80352\n",
      "batch index:  8  mse= 4.8035126\n",
      "batch index:  9  mse= 4.803506\n",
      "batch index:  10  mse= 4.8034997\n",
      "batch index:  11  mse= 4.8034935\n",
      "batch index:  12  mse= 4.803488\n",
      "batch index:  13  mse= 4.803481\n",
      "batch index:  14  mse= 4.8034763\n",
      "batch index:  15  mse= 4.8034706\n",
      "batch index:  16  mse= 4.8034644\n",
      "batch index:  17  mse= 4.8034587\n",
      "batch index:  18  mse= 4.8034544\n",
      "batch index:  19  mse= 4.803449\n",
      "batch index:  20  mse= 4.803444\n",
      "epoch:  9  mse= 4.8034396\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "learning_rate = 0.1\n",
    "\n",
    "# 创建占位符节点\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name='X')\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name='y')\n",
    "\n",
    "batch_size = 1000\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "# 创建batch\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index) \n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "    return scaler_housing_data_plus_bias[indices] , housing.target.reshape(-1, 1)[indices]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            print('batch index: ', batch_index, ' mse=', mse.eval())\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        print('epoch: ', epoch, ' mse=', mse.eval())\n",
    "    best_theta = theta.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存和恢复模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0  mse= 12.300475\n",
      "epoch:  100  mse= 4.8090396\n",
      "epoch:  200  mse= 4.80364\n",
      "epoch:  300  mse= 4.8032956\n",
      "epoch:  400  mse= 4.803259\n",
      "epoch:  500  mse= 4.803254\n",
      "epoch:  600  mse= 4.8032546\n",
      "epoch:  700  mse= 4.8032537\n",
      "epoch:  800  mse= 4.803254\n",
      "epoch:  900  mse= 4.803254\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.1\n",
    "\n",
    "X = tf.constant(scaler_housing_data_plus_bias, dtype=tf.float32, name='X')\n",
    "y = tf.constant(housing.target.reshape(-1, 1), dtype=tf.float32, name='y')\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# saver\n",
    "saver = tf.train.Saver()\n",
    "# 按照变量名保存和恢复变量\n",
    "# saver = tf.train.Saver({'weight': theta})\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print('epoch: ', epoch, ' mse=', mse.eval())\n",
    "            saver.save(sess, 'model.ckpt')\n",
    "        sess.run(training_op)\n",
    "    \n",
    "    best_theta = theta.eval()\n",
    "    saver.save(sess, 'model_final.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from model_final.ckpt\n",
      "4.8032537\n"
     ]
    }
   ],
   "source": [
    "# 恢复\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'model_final.ckpt')\n",
    "    mse = sess.run(mse)\n",
    "    print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用TensorBoard来可视化图和训练曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'\\n\\r\\n\\x06MSE_23\\x15b6\\x01A'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15\\xc2\\xdb\\x9e@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15X\\x1c\\xa8@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15\\x93\\xed\\xac@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15<(\\xa3@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15&\\x05\\xa1@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15yL\\xa2@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15\\xbco\\x9d@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15\\x0e\\xc1\\x97@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15R1\\x9f@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15d\\x8c\\xa1@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15F\\xa4\\xa1@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15\\xbe(\\x9e@'\n",
      "b\"\\n\\r\\n\\x06MSE_23\\x15'\\x97\\x98@\"\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15Ho\\x91@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15\\xf1\\x8c\\x98@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15s\\x99\\x9f@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15\\xdf\\x1e\\x98@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15\\xfc\\xdd\\x95@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15`\\xb6\\x95@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15d\\xa5\\x9b@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15RJ\\x99@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15h\"\\x9e@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15\\xf6\\xb9\\x95@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15;\\x81\\x99@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15\\xfaz\\x9a@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15l\\xe5\\x98@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15u\\xa8\\x96@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15\\xb2Y\\x9b@'\n",
      "b'\\n\\r\\n\\x06MSE_23\\x15\\x04\\t\\x99@'\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now = datetime.utcnow().strftime('%Y%m%d%H%M%S')\n",
    "root_logdir = 'tf_logs'\n",
    "logdir = '{}/run-{}/'.format(root_logdir, now)\n",
    "\n",
    "n_epochs = 10\n",
    "learning_rate = 0.1\n",
    "\n",
    "# 创建占位符节点\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name='X')\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name='y')\n",
    "\n",
    "batch_size = 1000\n",
    "n_batches = int(np.ceil(m / batch_size))\n",
    "\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0), name='theta')\n",
    "y_pred = tf.matmul(X, theta, name='predictions')\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# 创建batch\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index) \n",
    "    indices = np.random.randint(m, size=batch_size)\n",
    "    return scaler_housing_data_plus_bias[indices] , housing.target.reshape(-1, 1)[indices]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                print(summary_str)\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "    best_theta = theta.eval()\n",
    "    file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 启动 tensorboard 服务器\n",
    "```\n",
    "tensorboard --logdir tf_logs/\n",
    "```\n",
    "- 浏览器中输入 [http://localhost:6006]() 即可看到 tensorboard 界面"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 命名作用域"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_loss/sub\n",
      "my_loss/mse\n"
     ]
    }
   ],
   "source": [
    "# 在这个作用域中定义的每个操作现在都有一个 ‘my_loss/’ 前缀\n",
    "with tf.name_scope('my_loss') as scope:\n",
    "    error = y_pred - y\n",
    "    mse = tf.reduce_mean(tf.square(error), name='mse')\n",
    "    \n",
    "print(error.op.name)\n",
    "print(mse.op.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模块化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    w_shape = (int(X.get_shape()[1]), 1)\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name='weights')\n",
    "    b = tf.Variable(0.0, name='bias')\n",
    "    z = tf.add(tf.matmul(X, w), b, name='z')\n",
    "    \n",
    "    return tf.maximum(z, 0., name='relu')\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name='output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 共享变量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果想要在图的不同组件中共享变量：\n",
    "- 最简单的做法是先创建，然后将其作为参数传递给需要他的函数。但是，如果有太多的类似的共享参数，则参数传递便会很痛苦\n",
    "    ```\n",
    "    def relu(X, threshold):\n",
    "    ```\n",
    "\n",
    "- 也可以在第一次调用时将共享变量设置为函数的一个属性\n",
    "    ```\n",
    "    def relu(X):\n",
    "        if not hasattr(relu, 'threshold'):\n",
    "            relu.threshold = tf.Variable(0.0, name='max')\n",
    "    ```\n",
    "    \n",
    "- TF提供：\n",
    "    如果共享变量不存在，该方法先通过get_variable()函数创建共享变量；如果已经存在了，就复用该共享变量。期望的行为通过当前variable_scope()的一个属性来控制（创建或者复用）\n",
    "    ```\n",
    "    with tf.variable_scope('relu'):\n",
    "        threshold = tf.get_variable('threshold', shape=(), initializer=tf.constant_initilizer(0.0))\n",
    "    ```\n",
    "    如果这个变量之前已经被get_variable()调用创建过，这里会抛出一个异常。这种机制避免由于误操作而复用变量。如果要复用一个变量，需要通过设置变量作用域的reuse属性为True来显式的实现\n",
    "    ```\n",
    "    with tf.variable_scope('relu', reuse=True):\n",
    "        threshold = tf.get_variable('threshold')\n",
    "    ```\n",
    "    这段代码会获取既有的‘relu/threshold’变量，如果该变量不存在，或者在调用get_variable()时没有创建成功，那么会抛出一个异常"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    w_shape = (int(X.get_shape()[1]), 1)\n",
    "    w = tf.Variable(tf.random_normal(w_shape), name='weights')\n",
    "    b = tf.Variable(0.0, name='bias')\n",
    "    z = tf.add(tf.matmul(X, w), b, name='z')\n",
    "    with tf.variable_scope('relu', reuse=True):\n",
    "        threshold = tf.get_variable('threshold')\n",
    "    return tf.maximum(z, threshold, name='max')\n",
    "\n",
    "n_features = 3\n",
    "X = tf.placeholder(tf.float32, shape=(None, n_features), name='X')\n",
    "with tf.variable_scope('relu', reuse=tf.AUTO_REUSE):\n",
    "      threshold = tf.get_variable('threshold', shape=(), initializer=tf.constant_initializer(0.0))\n",
    "relus = [relu(X) for i in range(5)]\n",
    "output = tf.add_n(relus, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
